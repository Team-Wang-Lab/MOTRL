% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MODTRtree.R
\name{MODTRtree}
\alias{MODTRtree}
\title{Multi-Objective Tree-based Reinforcement Learning for estimating optimal DTR.}
\usage{
MODTRtree(
  Ys,
  w,
  A,
  H,
  delta = 0,
  tolerate = TRUE,
  pis.hat = NULL,
  m.method = c("AIPW", "randomForest"),
  mus.reg = NULL,
  depth = 5,
  lambda.pct = 0.05,
  minsplit = 20,
  lookahead = F
)
}
\arguments{
\item{Ys}{A matrix of outcomes of interest. The number of column is the number of objectives. Each columns contains the value of outcome of that objective for all subjects.}

\item{w}{A vector of weights for each objectives.}

\item{A}{A vector of observed treatment options.}

\item{H}{A matrix of covariates before assigning final treatment, excluding previous treatment variables.}

\item{delta}{A scalar indicates the minimum loss in pseudo-outcome that can be tolerated. The default value is 0. (non-tolerant)}

\item{tolerate}{A Boolean indicates whether the DTR tree is a tolerant tree or not.}

\item{pis.hat}{Estimated propensity score matrix.}

\item{m.method}{Method for calculating estimated conditional mean.}

\item{mus.reg}{Regression-based conditional mean outcome.}

\item{depth}{Maximum tree depth.}

\item{lambda.pct}{Minimal percent change in purity measure for split.}

\item{minsplit}{Minimal node size.}

\item{lookahead}{Whether or not to look into a further step of splitting to find the best split.}
}
\value{
Multi-Objective DTR Tree
}
\description{
a tree-based reinforcement learning (T-RL) method to directly
estimate multi-objective optimal DTRs in a multi-stage multi-treatment setting.
The tree can be gorwn as a tolerant tree, where the tolerant rate can be defined by user.
At each stage, T-RL builds an unsupervised decision tree that directly handles
the problem of optimization with multiple treatment comparisons, through a
purity measure constructed with augmented inverse probability weighted estimators.
}
